{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7.1 Discriminant functions\n",
    "\n",
    "In the previous chapter, we explored how to extract a feature vector $\\textbf{x} = [x_1, x_2, \\ldots, x_n]^T$ to describe an image object or *region*. In this chapter, our goal is **to classify the object as belonging to one of $M$ object classes or categories**, according to said feature vector $\\textbf{x}$. In other words, we pursuit the design of a mapping between features and categories $ \\textbf{x}^n \\rightarrow C$ where $C \\in \\{C_1,\\dots, C_{M}\\}$ (see Fig 1.). $\\\\[15pt]$\n",
    "\n",
    "<center>\n",
    "<div>\n",
    "    <div style=\"display:inline-block; width:50%;\">\n",
    "        <img src=\"./images/object_recognition_coco.png\" >$\\\\[3pt]$\n",
    "    </div>\n",
    "    <div style=\"display:inline-block; width:40%;vertical-align:top;margin-left:10px;\">\n",
    "        Scenario: A computer vision system in charge of classifying the objects within kitchens. The considered categories are: $C_1=\\text{fridge}$, $C_2=\\text{bowl}$, $C_3=\\text{microwave}$, $C_4=\\text{oven}$, $C_5=\\text{toaster}$, $C_6=\\text{spoon}$.\n",
    "        <br /><br />\n",
    "        Results of object classification: <br /><br />\n",
    "        $$\n",
    "        \\begin{array}\n",
    "        _x^1 = [x^1_1, x^1_2, \\ldots, x^1_n]^T \\rightarrow C^1 = C_4 \\\\\n",
    "        x^2 = [x^2_1, x^2_2, \\ldots, x^2_n]^T \\rightarrow C^2 = C_1 \\\\\n",
    "        x^3 = [x^3_1, x^3_2, \\ldots, x^3_n]^T \\rightarrow C^3 = C_3 \\\\\n",
    "        x^4 = [x^4_1, x^4_2, \\ldots, x^4_n]^T \\rightarrow C^4 = C_5 \\\\\n",
    "        \\end{array}\n",
    "        $$\n",
    "    </div>    \n",
    "</div>\n",
    "    <figcaption>Fig 1. Example of object classification within the COCO dataset.</figcaption>\n",
    "</center>$\\\\[1pt]$\n",
    "\n",
    "For that, the space defined by the features in $\\textbf{x}$, also referred as **feature space**, is divided into prediction regions. The image below shows an example of those regions in a scenario with categories $C=\\{C_1,C_2,C_3\\}$, so $M=3$, and features $\\textbf{x}=[x_1,x_2]^T$:\n",
    "$\\\\[10pt]$\n",
    "\n",
    "<center>\n",
    "    <img src=\"./images/clas-space.png\" width=\"300\">\n",
    "    <figcaption>Fig 2. Example of a feature space with three regions.</figcaption>\n",
    "</center>$\\\\[3pt]$\n",
    "\n",
    "Two main steps are needed in order to build an object recognition system and work with it:\n",
    "\n",
    "- A **training (design) phase**, where sample vectors of known objects are used to learn the classifier (supervised learning).\n",
    "- A **prediction (online) phase**, where the image objects are classified as belonging to one of the classes based on the learned prediction models.\n",
    "\n",
    "Such prediction models come in two flavors:\n",
    "\n",
    "- **Statistical classifiers:**\n",
    "  - It is assumed that the feature vectors $\\textbf{x}$ of the classes $C$ follow a **statistical distribution**.\n",
    "  - The parameters of such distribution need to be **learned from known objects**.\n",
    "  - Examples: Naïve Bayessian Classifier, Logistic Regression, Conditional Random Fields.  \n",
    "- **Non-statistical classifiers:**\n",
    "  - No assumption is made on the statistical distribution of the feature vector.\n",
    "  - The coefficient of deterministic discriminant functions are learned.\n",
    "  - Examples: Support Vector Machine, Perceptron, AdaBoost, Neural Networks, Genetic algorithms.\n",
    "\n",
    "This notebook focuses on non-statistical classifiers. Concretely it covers:\n",
    "\n",
    "- Linear discriminant functions (<a href=\"#711\">section 7.1.1</a>).\n",
    "- The concept of separability (<a href=\"#712\">section 7.1.2</a>).\n",
    "- Generalized discriminant functions (<a href=\"#713\">section 7.1.3</a>).\n",
    "\n",
    "All these methos are under the Machine Learning (ML) umbrela. If you want to give a try to Deep Learning (DL) ones, you can do it in notebook *7.5 Deep Learning methods for object detection*!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem context - Traffic sign recognition\n",
    "\n",
    "Before self-driving vehicles can truly operate autonomously, they would need to identify traffic signs like \"speed limit\", \"school ahead\" or \"turn ahead\". This problem is called **Traffic Sign Recognition (TSR)** and is faced by companies like Tesla or Google (Waymo), and now by *AliquindoiCars*, a startup located in the Andalusia Technology Park in Málaga.\n",
    "\n",
    "TSR is part of the features collectively called *Advanced Driver Assistance Systems (ADAS)*. It uses image processing techniques to detect the traffic signs. The detection methods used can be generally divided into color based, shape based, or those using low level features. $\\\\[3pt]$\n",
    "\n",
    "<img src=\"./images/signs.jpg\" width=\"400\">$\\\\[3pt]$\n",
    "\n",
    "Given your growing experience in computer vision, *AliquindoiCars* contacted you asking for a TSR technique to be integrated into a self-driving car. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "matplotlib.rcParams['figure.figsize'] = (8.0, 8.0)\n",
    "\n",
    "images_path = './images/'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### The data\n",
    "\n",
    "Since most traffic signs in Spain (and in the rest of the world) have a rectangular, circular or triangular shape, they provided you 3 folders containing 20 images each;\n",
    "\n",
    "- `./images/circles/{0-19}.png`\n",
    "- `./images/squares/{0-19}.png`\n",
    "- `./images/triangles/{0-19}.png`\n",
    "\n",
    "These folders contain segmented and binarized images of traffic signs captured by a camera in a car. **Our task is to design a recognition system able to distinguish each type of shape**.\n",
    "\n",
    "Let's take a look at some of these images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load images\n",
    "img_circle = cv2.imread(images_path + \"circles/0.png\", 0)\n",
    "img_square = cv2.imread(images_path + \"squares/0.png\", 0)\n",
    "img_triangle = cv2.imread(images_path + \"triangles/0.png\", 0)\n",
    "\n",
    "# Show them!\n",
    "plt.subplot(131)\n",
    "plt.imshow(img_circle,cmap='gray');\n",
    "plt.title('Circular shape')\n",
    "\n",
    "plt.subplot(132)\n",
    "plt.imshow(img_square,cmap='gray');\n",
    "plt.title('Rectangular shape')\n",
    "\n",
    "plt.subplot(133)\n",
    "plt.imshow(img_triangle,cmap='gray');\n",
    "plt.title('Triangular shape');"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Computing feature vectors\n",
    "\n",
    "Prior to describe the methods that will be used to perform recognition, let's build the feature vectors they are going to use. For this, and given your experience, you are going to use the Hu Moments, a 7-size feature vector that looks like $\\textbf{x} = [v_1, v_2, v_3, v_4, v_5, v_6, v_7]^T$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **<span style=\"color:green\"><b><i>ASSIGNMENT 1: Computing the features</i></b></span>**\n",
    "\n",
    "**Your first task is** to obtain a $20x7$ matrix for each type of shape, where rows index images and columns Hu moments. In this way, the $5^{th}$ row in the matrix characterizing rectangular signs would contain the Hu moments computed from the $5^{th}$ image with that shape. \n",
    "\n",
    "In order to get a first-hand impression of how these features are distributed in the feature space for the different shapes, plot the results using [`plt.scatter()`](https://matplotlib.org/3.2.1/api/_as_gen/matplotlib.pyplot.scatter.html) (show only the firsts 2 Hu moments)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assignment 1\n",
    "def image_moments(region):\n",
    "    \"\"\" Compute moments of the external contour in a binary image.   \n",
    "    \n",
    "        Args:\n",
    "            region: Binary image\n",
    "                    \n",
    "        Returns: \n",
    "            moments: dictionary containing all moments of the region\n",
    "    \"\"\"   \n",
    "    \n",
    "    # Get external contour\n",
    "    contours,_ = cv2.findContours(region,cv2.RETR_EXTERNAL ,cv2.CHAIN_APPROX_NONE)\n",
    "    cnt = contours[0]\n",
    "    \n",
    "    # Compute moments\n",
    "    moments = cv2.moments(cnt)\n",
    "    \n",
    "    return moments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute Hu moments for circle shape\n",
    "hu_circles = np.zeros((20,7))\n",
    "\n",
    "for i in range(20):\n",
    "    img = cv2.imread(images_path + \"circles/\" + str(None) + \".png\", 0)\n",
    "    moments = image_moments(None)\n",
    "    hu_circles[None,None] = cv2.HuMoments(None).flatten()\n",
    "\n",
    "# Compute Hu moments for square shape\n",
    "hu_squares = np.zeros((20,7))\n",
    "\n",
    "for i in range(20):\n",
    "    img = cv2.imread(images_path + \"squares/\" + str(None) + \".png\", 0)\n",
    "    moments = image_moments(None)\n",
    "    hu_squares[None,None] = cv2.HuMoments(None).flatten()\n",
    "\n",
    "# Compute Hu moments hor triangle shape\n",
    "hu_triangles = np.zeros((20,7))\n",
    "\n",
    "for i in range(20):    \n",
    "    img = cv2.imread(images_path + \"triangles/\" + str(None) + \".png\", 0)\n",
    "    moments = image_moments(None)\n",
    "    hu_triangles[None,None] = cv2.HuMoments(None).flatten()\n",
    "\n",
    "# Define plot axis\n",
    "plt.axis([0.15, 0.2, -0.0005, 0.0015])\n",
    "\n",
    "# Plot firsts two Hu moments\n",
    "plt.xlabel(\"First Hu moment\")\n",
    "plt.ylabel(\"Second Hu moment\")\n",
    "plt.scatter(hu_triangles[None,None],hu_triangles[None,None],marker=\"^\")\n",
    "plt.scatter(hu_circles[None,None],hu_circles[None,None], marker=\"o\")\n",
    "plt.scatter(hu_squares[None,None],hu_squares[None,None], marker=\"s\");"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Interlude\n",
    "\n",
    "**You must save the computed Hu moments of the segmented data**, since we are going to need them in the next notebook. For saving numPy matrices, you can use [`np.save()`](https://docs.scipy.org/doc/numpy/reference/generated/numpy.save.html) (data is saved at `./data/` by default)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"./data/hu_circles.npy\",hu_circles)\n",
    "np.save(\"./data/hu_triangles.npy\",hu_triangles)\n",
    "np.save(\"./data/hu_squares.npy\",hu_squares)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.1.1 Linear discriminant functions <a id=\"711\"></a>\n",
    "\n",
    "Taking a look at the scatter plot resultant from the previous assignment, we can see how the three types of signs could be segmented using 2 lines. For example: $\\\\[10pt]$\n",
    "\n",
    "<center>\n",
    "    <img src=\"./images/plot_linear.jpg\" width=\"350\">$\\\\[3pt]$\n",
    "    <figcaption>Fig 3. First two moments of the binarized traffic signs and a possible division into regions.</figcaption>\n",
    "</center>\n",
    "\n",
    "And that's what **linear discriminant functions** do! \n",
    "\n",
    "Let's start by describing how such lines could be represented. As we know, a way to define a 2D line is:\n",
    "\n",
    "$\\hspace{2cm} 0 = Ax + By + C\\\\[3pt]$  \n",
    "Using another notation:$\\\\[5pt]$  \n",
    "$\\hspace{2cm}0 = w_1x_1 + w_2x_2 + w_3$$\\\\[3pt]$  \n",
    "\n",
    "Note that we can generalize this 2D line to any dimension hyperplane:$\\\\[5pt]$  \n",
    "$\\hspace{2cm}0 = w_1x_1 + w_2x_2 + \\ldots + w_nx_n + w_{n+1}1\\ =\\ \\sum_{i=1}^{n+1}w_ix_i$$ \\ =\\ w^T\\cdot x\\\\[1pt]$  \n",
    "In this way, we can divide the feature space for any dimension (e.g. n = 7 for Hu moments)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Working with two classes\n",
    "\n",
    "If we are considering just two classes $C=\\{C_1,C_2\\}$ (*e.g.* an object in a kitchen could be a spoon or a fork), we can define a linear discriminant function as:\n",
    "\n",
    "$\\hspace{2cm} d(\\mathbf{x}) = \\mathbf{w}^T \\cdot \\mathbf{x} \\ \\ \\ \\ \\ \\text{(dot product of both vectors)}$\n",
    "\n",
    "Formally, the vector $w$ is called **weight vector**, and is computed automatically from a set of data called **training data** using techniques like Logistic Regression, Support Vector Machines, or Perceptron.\n",
    "\n",
    "In this way, when we have a new object characterized by $\\mathbf{x'}$ to classify, $d(\\mathbf{x'})$ is computed and:\n",
    "- If $d(\\mathbf{x'})\\ge 0$ the new object is assigned $C_1$, and\n",
    "- if $d(\\mathbf{x'})\\lt 0$ the object is assigned to $C_2$.\n",
    "\n",
    "We say that the linear discriminant function $d(\\mathbf{x'})$ works as a **decision boundary** between both classes. The following figure illustrates this (blue dots represent characterized objects belonging to $C_1$, while red ones those belonging to $C_2$). $\\\\[6pt]$\n",
    "\n",
    "<center>\n",
    "<img src=\"./images/linear_discriminant_function_2_categories.png\" width=\"350\">\n",
    "    <figcaption>Fig 3. A decision boundary defined by a decision function that divides the feature space into two regions.</figcaption>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **<span style=\"color:green\"><b><i>ASSIGNMENT 2. Classifying samples</i></b></span>**\n",
    "\n",
    "Let's play a bit with a toy example of a linear discriminant function. Consider that the learned weights during the training phase of the classifier are $\\mathbf{w} = [1,0,-3]^T$, so the linear discriminant function looks like $d(\\mathbf{x}) = 1x_1 + 0x_2 -3$. \n",
    "\n",
    "**Your task is to:** \n",
    "\n",
    "- classify some 2D data using the previous discriminant function (for that, use a combination of [`np.dot()`](https://numpy.org/doc/stable/reference/generated/numpy.dot.html) and [`np.sign()`](https://numpy.org/doc/stable/reference/generated/numpy.sign.html)),  and\n",
    "- plot them with different colors depending on their assigned class using [`plt.scatter()`](https://matplotlib.org/3.2.1/api/_as_gen/matplotlib.pyplot.scatter.html) and its `c` argument. \n",
    "\n",
    "*Tip: [how to color a data point using its class](https://stackoverflow.com/questions/43579626/pandas-plot-with-positive-values-one-color-and-negative-values-another)*."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define weight vector\n",
    "w = np.array([[1],[0],[-3]])\n",
    "\n",
    "# Define data matrix\n",
    "data = np.array([[2,2,1],[1,2,1],[2,1,1],[5,4,1],[4,5,1],[4,4,1]])\n",
    "\n",
    "# Compute class for each data\n",
    "classification = np.dot(None,None)\n",
    "class_ = np.sign(None)\n",
    "\n",
    "# Plot classified data\n",
    "plt.scatter(None,None,c=None.flatten(), cmap=\"bwr\")\n",
    "\n",
    "# Plot discriminant line\n",
    "x = np.linspace(3, 3, 1000)\n",
    "y = np.linspace(0, 5, 1000)\n",
    "plt.plot(x,y);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Scenarios with N-classes\n",
    "\n",
    "The previous idea can be generalized to an arbitrary number of classes, defining in that case hyper-planes in a n-dimensional space:\n",
    "\n",
    "$\\hspace{2cm}d_i(\\mathbf{x}) = w^i_1x_1 + w^i_2x_2 + \\ldots + w^i_nx_n + w^i_{n+1}\\ =\\ \\mathbf{w^i}^T\\cdot \\mathbf{x}\\\\[1pt]$  \n",
    "\n",
    "In this case, the object is assigned to the category which discriminant function returns the highest value. That is:\n",
    "\n",
    "<img src=\"./images/linear_discriminant_functions_general_case_low.png\">$\\\\[3pt]$\n",
    "\n",
    "When more than 2 classes are considered, **the discriminant functions are no longer the decision boundaries between classes**. However, the decision boundary between classes $C_i$ and $C_j$ can be computed as:\n",
    "\n",
    "$\\hspace{2cm}d_{ij}(\\mathbf{x}) = d_i(\\mathbf{x})-d_j(\\mathbf{x})=(\\mathbf{w}_i^T-\\mathbf{w}_j^T) \\cdot \\mathbf{x} = \\mathbf{w}_{ij}^T \\cdot \\mathbf{x}$\n",
    "\n",
    "The following image shows an example with 3 classes (notice that it also exists a decision boundary between classes 1 and 3, $d_{13}(\\mathbf{x})$, but it has been omitted for clarity).$\\\\[10pt]$\n",
    "\n",
    "<center>\n",
    "<img src=\"./images/2lines-discriminant.png\"  width=\"350\">\n",
    "<figcaption>Fig 4. Decision boundaries between 3 categories.</figcaption>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.1.2 Separability <a id=\"712\"></a>\n",
    "\n",
    "An important concept regarding object recognition is such of **separability**. In this way, two sets of points defining two classes may be separable or not in a given dimension (e.g. $x_1$, $x_2$, etc.).  \n",
    "\n",
    "Two sets are **linearly separable** if it exists at least one line in the plane that leaves all the points belonging to one class on one side of the line and all those belonging to the second class on the other side. This idea immediately generalizes to higher-dimensional Euclidean spaces if the line is replaced by a hyperplane. \n",
    "\n",
    "Some illustrative examples of this:\n",
    "\n",
    "<img src=\"./images/separability-2.png\" >$\\\\[3pt]$\n",
    "\n",
    "- As you can see, those classes are separable. Also, if only dimension $x_1$ is used, we can separate the classes as well. This is not recomended because there isn't a clear separation using only $x_1$, and $x_2$ is also **discriminative**, that is, it also provides valuable information for separating both classes.\n",
    "\n",
    "<img src=\"./images/separability-1.png\" >$\\\\[3pt]$\n",
    "\n",
    "- In this example the classes are not separable as they overlap in both dimensions. Additionally, we can see that $x_1$ is not discriminative as it doesn't provide any information for separating those classes. The addition of a third dimension/feature could fix this!\n",
    "\n",
    "<img src=\"./images/separability-3.png\" >$\\\\[3pt]$\n",
    "\n",
    "- This is an example of a non-linear separable problem. The classes can't be separated using a line, but a **generalized discriminant function** could do it. We will see this later in this notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Back to sign shape recognition\n",
    "\n",
    "Back to our traffic sign shape recognition problem, **we are trying to separate** the usual shapes of traffic signs using the Hu moments. As a first approximation to this problem, we plotted the first and second Hu moments ($x_1$ and $x_2$) in order to analyze them. You should have obtained something like this:\n",
    "\n",
    "<center>\n",
    "     <img src=\"./images/separability-4.png\" width=\"500\">$\\\\[3pt]$\n",
    "    <figcaption>Fig 5. Result of plotting the two first Hu moments computed from the images in our train data.</figcaption>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color=\"blue\"><b><i>Thinking about it (1)</i></b></font>\n",
    "\n",
    "**Now you are in a good position to answer these questions:**\n",
    "\n",
    "- Is this problem linearly separable?\n",
    "\n",
    "    <p style=\"margin: 4px 0px 6px 5px; color:blue\"><i>Your answer here!</i></p>\n",
    "    \n",
    "- Are the classes separable using only the first Hu moment ($x_1$)?\n",
    "\n",
    "    <p style=\"margin: 4px 0px 6px 5px; color:blue\"><i>Your answer here!</i></p>\n",
    "    \n",
    "- Are the classes separable using only the second Hu moment ($x_2$)?\n",
    "\n",
    "    <p style=\"margin: 4px 0px 6px 5px; color:blue\"><i>Your answer here!</i></p>\n",
    "    \n",
    "- Which dimension is more discriminative?\n",
    "\n",
    "    <p style=\"margin: 4px 0px 6px 5px; color:blue\"><i>Your answer here!</i></p>\n",
    "    \n",
    "- Would be *AliquindoiCars* guys happy if we propose a solution for shape classification based on linear discriminant functions?\n",
    "  \n",
    "    <p style=\"margin: 4px 0px 6px 5px; color:blue\"><i>Your answer here!</i></p>    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.1.3 Generalized discriminant function <a id=\"713\"></a>\n",
    "\n",
    "As we saw in the previous section, some classes are not separable using a linear discriminant function. In those cases, we may need a **linear basis function model**, also called **generalized discriminant function**, which permit us to use non-linear functions to separate classes (notice that, despite of this, the problem may still not be separable).\n",
    "\n",
    "The idea behind these discriminant functions is to transform the $\\textbf{x}$ space into a $\\textbf{x' = f(x)}$ space ($dim(x) \\lt dim(x')$):$\\\\[5pt]$\n",
    "\n",
    "$$d(x) = w_1\\ \\color{blue}{f_1(x)} + w_2\\ \\color{blue}{f_2(x)} + \\ldots + w_k\\ \\color{blue}{f_k(x)} + w_{k+1} = \\sum_{i=1}^{k+1}w_i\\ \\underbrace{\\color{blue}{f_i(x)}}_{\\scriptsize\\text{New space}}=\\mathbf{w}^T\\cdot \\mathbf{f}(\\mathbf{x})$$\n",
    "\n",
    "$$d(x) = w_1\\ \\color{blue}{x_1'} + w_2\\ \\color{blue}{x_2'} + \\ldots + w_k\\ \\color{blue}{x_k'} + w_{k+1} = \\sum_{i=1}^{k+1}w_i\\ \\color{blue}{x_i'} = w^T \\cdot \\color{blue}{x'}=d'(\\mathbf{x}')$$\n",
    "\n",
    "Thereby:\n",
    "\n",
    "$$\n",
    "\\left.\\begin{aligned}\n",
    "        \\mathbf{x'} = \\mathbf{f}(\\mathbf{x}) &= [f_1(\\mathbf{x}) \\ \\ \\ f_2(\\mathbf{x}) \\ \\ \\ \\cdots \\ \\ \\ f_k(\\mathbf{x}) \\ \\ \\  1]^T\\\\\n",
    "        \\mathbf{w} &= [w_1 \\ \\ \\ w_2 \\ \\ \\ \\cdots \\ \\ \\ w_k \\ \\ \\ w_{k+1}]^T\n",
    "       \\end{aligned}\n",
    " \\right\\}\n",
    " \\ \\  d(\\mathbf{x})= \\mathbf{w}^T \\cdot \\mathbf{x} = \\mathbf{w}^T \\cdot \\mathbf{f}(\\mathbf{x})\n",
    "$$\n",
    " \n",
    " being $\\mathbf{f}(\\mathbf{x})$ the basis functions!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **<span style=\"color:green\"><b><i>ASSIGNMENT 3: Transforming between spaces</i></b></span>**\n",
    "\n",
    "Let's practice this transformation between spaces. **What to do?** You have to complete the method `transform_space()`, which transforms a set of 2D points into a new space defined by:\n",
    "\n",
    "$$x' = [x_1^2, \\ x_1x_2, \\ x_2^2, \\ x_1, \\ x_2, \\ 1]$$\n",
    "\n",
    "The input set of points is a matrix with shape $(n\\_data,2)$, and the output is another matrix with shape $(n\\_data,6)$, being $n\\_data$ the number of points in the set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assignment 3\n",
    "def transform_space(data_points):\n",
    "    \"\"\" Compute moments of the external contour in a binary image.   \n",
    "    \n",
    "        Args:\n",
    "            data_points: Input matrix containing a set of 2D points\n",
    "                    \n",
    "        Returns: \n",
    "            fx: set of points transformed to a quadratic space\n",
    "    \"\"\"  \n",
    "    \n",
    "    n_data = data_points.shape[None]\n",
    "    \n",
    "    fx = np.zeros((None,None))\n",
    "    \n",
    "    for i in range(n_data):\n",
    "        \n",
    "        x1 = data_points[None,None]\n",
    "        x2 = data_points[None,None]\n",
    "        \n",
    "        fx[i,:] = [None, None, None, None, None, None]\n",
    "        \n",
    "    return fx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You can use next code to **test if the results are correct**:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = np.array([[2,3],[1,2],[2,7],[2,4],[1,5],[2,4]])\n",
    "\n",
    "x = transform_space(data)\n",
    "\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<font color='blue'>**Expected output:**  </font>\n",
    "\n",
    "     [[ 4.  6.  9.  2.  3.  1.]\n",
    "     [ 1.  2.  4.  1.  2.  1.]\n",
    "     [ 4. 14. 49.  2.  7.  1.]\n",
    "     [ 4.  8. 16.  2.  4.  1.]\n",
    "     [ 1.  5. 25.  1.  5.  1.]\n",
    "     [ 4.  8. 16.  2.  4.  1.]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **<span style=\"color:green\"><b><i>ASSIGNMENT 4: Classifying in the transformed space</i></b></span>**\n",
    "\n",
    "Finally, we will see a toy example of a non-linear discriminant function in action. Concretely, we will consider a quadratic function, $d(x)=x_1^2-5x_2$ (so $k=5$), in a two classes problem with $\\mathbf{x}=[x_1 \\ \\ x_2]$. Thereby, the vector of features in the new space is:\n",
    "\n",
    "$\\hspace{2cm}  \\mathbf{x'}=[x_1^{'},\\dots,x_6^{'}]=[x_1^2 \\ \\ x_1x_2 \\ \\ x_2^2 \\ \\ x_1 \\ \\ x_2 \\ \\ 1]^T $ <br />\n",
    "so:\n",
    "- $x_1^2=f_1(\\mathbf{x})=x_1'$\n",
    "- $x_1 x_2=f_2(\\mathbf{x})=x_2'$\n",
    "- and so on.\n",
    "\n",
    "and the vector of weights turns out to be:\n",
    "\n",
    "$\\hspace{2cm} \\mathbf{w}=[1,0,0,0,-5,0]$.\n",
    "\n",
    "As for the new discriminant function we get:\n",
    "\n",
    "$\\hspace{2cm} d(\\mathbf{x}) = w_1 \\cdot x_1' + w_5 \\cdot x_5'$\n",
    "\n",
    "**Your task is to classify some 2D data** using the previous discriminant function and plot them coloring each point with a color depending on its class. For that, you can rely on the [`np.dot()`](https://numpy.org/doc/stable/reference/generated/numpy.dot.html), [`np.sign()`](https://numpy.org/doc/stable/reference/generated/numpy.sign.html)), and [`plt.scatter()`](https://matplotlib.org/3.2.1/api/_as_gen/matplotlib.pyplot.scatter.html) functions previously used in the second assignment. \n",
    "\n",
    "*Tip: Remember to transform the data space before applying the dot product.*\n",
    "\n",
    "Expected results:\n",
    "\n",
    "<center>\n",
    "     <img src=\"./images/classification_in_the_transformed_space.png\">$\\\\[3pt]$\n",
    "    <figcaption>Fig 6. Classification of a number of samples in both, the original space and the transformed one.</figcaption>\n",
    "</center>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assignment 4\n",
    "\n",
    "# Define weight vector\n",
    "w = np.array([[1],[0],[0],[0],[-5],[0]])\n",
    "\n",
    "# Define data matrix\n",
    "data = np.array([[2,0.5],[1.5,0.25],[3,1],[1,1],[1,0.5],[2,1],[5,5.3],[4,3],[3,2]])\n",
    "\n",
    "# Trasform from the x space to a f(x) space\n",
    "transformed_data = transform_space(None)\n",
    "\n",
    "# Compute class for each data\n",
    "classification = np.dot(None,None)\n",
    "class_ = np.sign(None)\n",
    "\n",
    "# Plot classified data\n",
    "matplotlib.rcParams['figure.figsize'] = (15.0, 15.0)\n",
    "ax = plt.subplot(121)\n",
    "ax.set_aspect('equal')\n",
    "plt.title('Original space')\n",
    "plt.xlabel(\"x_1\")\n",
    "plt.ylabel(\"x_2\")\n",
    "plt.axis([-0.5, 6.5, -0.5, 7.5])\n",
    "plt.scatter(None,None,c=None.flatten(), cmap=\"bwr\")\n",
    "\n",
    "# Plot discriminant line\n",
    "x = np.linspace(0, 6, 1000)\n",
    "y = (w[0]*(x**2) + w[5])/-w[4]\n",
    "plt.plot(x,y);\n",
    "\n",
    "# Or equivalently plotting the data in the transformed space, \n",
    "# where the descision boundary defined by the discrimiant function defines a line\n",
    "ax = plt.subplot(122)\n",
    "ax.set_aspect('equal')\n",
    "plt.title('Transformed space')\n",
    "plt.xlabel(\"x'_1\")\n",
    "plt.ylabel(\"x'_2\")\n",
    "plt.axis([-1, 26, -10, 15])\n",
    "plt.scatter(None,None,c=None.flatten(), cmap=\"bwr\")\n",
    "\n",
    "# Plot discrimant line\n",
    "x = np.linspace(0, 27, 1000)\n",
    "y = (w[0]*(x) + w[5])/-w[4]\n",
    "plt.plot(x,y);\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "Well done! This was a mostly theoretical notebook, but it described the basis of object classification. You have learned so far:\n",
    "\n",
    "- how linear and non-linear discriminant functions work,\n",
    "- to classify objects in a scenario with an arbitrary number of belonging classes using multiple discriminant functions, and\n",
    "- to check if a feature space allows for the definition of discriminative classifiers looking at the separability between classes.\n",
    "\n",
    "In the following notebooks in this chapter we will see how to automatically retrieve the weight vector from a set o training data. Exciting, isn't?"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "position": {
    "height": "188.85px",
    "left": "1530px",
    "right": "20px",
    "top": "120px",
    "width": "303px"
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
